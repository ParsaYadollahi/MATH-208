---
title: "Assignment 3 MATH 208  (Question 1)"
output:
  pdf_document: default
  html_document: default
---
Prsa Yadollahi \newline
260869949 \newline
MATH 208 - Assignment 3\newline



```{r include=FALSE}
library(tidyverse)
library(knitr)
library(gridExtra)
library(readr)
library(dplyr)
HTRU2 <- 
  read_csv("./HTRU_2.csv",
           col_names=FALSE)
# Name the variables
names(HTRU2) = c("Mean_IP", "SD_IP", "EK_IP", "SKW_IP",
                 "Mean_DMSNR", "SD_DMSNR", "EK_DMSNR", "SKW_DMSNR", 
                 "Class")
```


(a)
```{r}
logistic_Regression = function(theta, x1, x2) {
  p = 1/(1+exp(-x1*theta[1] - x2*theta[2] - theta[3]))
  return(p)
}
```


(b)
```{r}
cross_entropy_loss = function(theta, x1, x2, y){
  p = logistic_Regression(theta, x1, x2)
  log_reg = 0
  # Negative sum from 1 to n
  for (i in seq_along(y)){
    single_pass = 
        y[i]*log(p[i]) + 
        (1-y[i])*log(1-p[i])
    log_reg = log_reg - single_pass
  }
  return(log_reg)
}
```


(c)
```{r}
loss_funct <- function(col1,col2){
  x1_d <- c(HTRU2[[col1]])
  x2_d <- c(HTRU2[[col2]])
  y_d <- c(HTRU2$Class)
  result<-optim(par=c(0,0,0), fn=cross_entropy_loss, x1=x1_d, x2=x2_d, y=y_d)
}

result = loss_funct(1,5)
result
# Thetas = -0.10569326 0.01629013 7.28979911
# Value = 1991.015
```

(d)
```{r}
var_combs<-combn(names(HTRU2[,-9]),2)
res = NULL
for(i in seq_along(names(HTRU2[1,]))){
  for(j in 1:8){
    if(j<=i){
      next
    }
    if(i == 8 & j == 8){
      break
    }
    cross_entropy <- loss_funct(i,j)
    cross_entropy_val <- cross_entropy$value
    table <- tibble(
      "col1" = var_combs[1,i],
      "col2" = var_combs[2,i],
      "cross entropy loss" = cross_entropy_val
    )
    res = bind_rows(table,res)
  }
}
kable(res[order(res$`cross entropy loss`),])
```

(e)
```{r}
var_combs = combn(names(HTRU2[,-9]),2)

loss_funct2 = function(columns){
  x1_d = c(HTRU2[[toString(columns[[1]])]])
  x2_d = c(HTRU2[[toString(columns[[2]])]])
  y_d = c(HTRU2$Class)
  
  result = optim(
              par=c(0,0,0),
              fn=cross_entropy_loss,
              x1 = x1_d,
              x2 = x2_d,
              y = y_d
            )
  
  table = tibble(
    "col1" = columns[[1]],
    "col2" = columns[[2]],
    "cross entropy loss" = result$value
  )
  return(table)
}
end_result = map_dfr(as.data.frame(var_combs), loss_funct2)
end_result = end_result[order(end_result$`cross entropy loss`),]
kable(end_result)
```































